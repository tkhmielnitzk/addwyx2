{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.17","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install python==3.9\n!pip install torch\n!pip install deepparse","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport random\n# import pytorch\nfrom deepparse.parser import AddressParser\nimport deepparse\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport shutil\n\nbool_new_model = True\ndirpath = os.path.join('checkpoints')\n\nif os.path.exists(dirpath) and os.path.isdir(dirpath) and bool_new_model:\n    shutil.rmtree(dirpath)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_rand_garbage(list_bloc):\n    list_garbage = ['',' ','École','Bibliothèque','Musée','Bureau de poste','Banque','Hôtel','Restaurant','Café','Cinéma','Théâtre',\n                    'Stade','Gymnase','Parc aquatique','Magasin de vêtements','Pharmacie','Épicerie','Salon de coiffure','Station service',\n                    'Garage','Boutique de jouets','Galerie d art','Studio de danse','Salle de concert','Centre commercial','Boulangerie',\n                    'Université','Poste de police','Caserne de pompiers','Église','Mosquée','Synagogue','Temple','Hôpital','Clinique','Cabinet médical',\n                    'Pharmacie','Maison de retraite','Centre de réadaptation','Salle de conférence','Salle d exposition',\n                    'School','Bibliotheek','Museum','Postkantoor','Bank','Hotel','Restaurant','Café','Bioscoop','Theater','Stadion',\n                    'Sportschool','Waterpark','Kledingwinkel','Apotheek','Kruidenierswinkel','Kapsalon','Tankstation','Garage','Speelgoedwinkel',\n                    'Kunstgalerie','Dansstudio','Concertzaal','Winkelcentrum','Bakkerij','Universiteit','Politiebureau','Brandweerkazerne',\n                    'Kerk','Moskee','Synagoge','Tempel','Ziekenhuis','Kliniek','Huisartsenpraktijk','Apotheek','Verpleeghuis','Revalidatiecentrum',\n                    'Conferentieruimte','Tentoonstellingsruimte']\n    garbage = random.choice(list_garbage)\n    list_extension = ['', ' de ' + list_bloc[4], ' van ' + list_bloc[4]]\n    extension = random.choice(list_extension)\n    if garbage == '': \n        return ''\n    else : \n        return garbage + extension\n    \ndef generate_rand_box(list_bloc):\n    list_box = ['','box','boite','BOITE','bte', 'b', 'bt']\n    str_box = random.choice(list_box)\n    if list_bloc[2] == '' or  list_bloc[2] is None: \n        return ''\n    else : \n        return str_box + ' ' + list_bloc[2] # TODO AJOUTER RANDOMNESS SUR SPACE ENTRE BOITE ET NUM DE BOITE\n\ndef del_symbols(list_bloc):\n    result = []\n    symbols = \"!@#$%^&*()_-+={}[]|\\:;'<>?,./\\\"\"\n    for item in list_bloc:\n        if item is not None:\n            new_item = ''.join([c if c.isalnum() or c.isspace() else ' ' for c in item])\n            result.append(new_item)\n        else :\n            result.append(None)\n    if (len(list_bloc) != len(result)):\n        raise str(len(list_bloc)) + ' != ' + str(len(result))\n    return result \n\ndef generate_rand_presence(list_bloc):\n    N = len(list_bloc)\n    random_list = [random.choices([0,1], [0.2,0.8])[0] for _ in range(N)]\n    return random_list\n\ndef generate_rand_order(list_bloc):\n    N = len(list_bloc)\n    unique_list = list(range(1, N + 1))\n    random.shuffle(unique_list)\n    return unique_list\n\ndef add_typo_error(list_bloc, list_order):\n    result = []\n    error_type = random.choice(['nothing','add', 'delete'])\n    if len(list_bloc) != len(list_order):\n        print(list_bloc)\n        raise str(list_bloc)\n    for i in range(len(list_bloc)):\n        string = list_bloc[i]\n        order = list_order[i]\n        if string is None:\n            pass\n        elif error_type == 'nothing' or order=='PostalCode' or len(string)<1: \n            pass\n        elif error_type == 'add':\n            error_index = random.randint(0, len(string))\n            error_char = random.choice('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ')\n            string = string[:error_index] + error_char + string[error_index:]\n        elif error_type == 'delete' and len(string)>1:\n            if len(string) > 0:\n                error_index = random.randint(0, len(string) - 1)\n                string = string[:error_index] + string[error_index+1:]\n        result.append(string)\n        \n    if (len(list_bloc) != len(result)):\n        raise str(list_bloc) + ' != ' + str(result)\n    return result\n\ndef generate_elem_category(list_bloc, list_order = ['StreetNumber','StreetName','Unit','PostalCode','Municipality','GeneralDelivery']):\n    list_elem_category = []\n    if len(list_bloc) != len(list_order):\n        print('il n\\'y a pas autant de blocs que de categories ' + str(len(list_bloc)) + ' != ' + str(len(list_order)))\n        raise 'il n\\'y a pas autant de blocs que de categories ' + str(len(list_bloc)) + ' != ' + str(len(list_order))\n    for i in range(len(list_bloc)):\n        bloc = list_bloc[i]\n        order = list_order[i]\n        if bloc is not None:\n            len_bloc = len(bloc.split())\n            elem_category = [order] * len_bloc\n            list_elem_category.append(elem_category)\n        else : \n            list_elem_category.append([order])\n    return list_elem_category\n\ndef change_list_order(lst, order):\n    if len(lst) != len(order):\n        raise ValueError(\"List and order must have the same length.\")\n    new_lst = [None] * len(lst)\n    for i, value in enumerate(lst):\n        new_index = order[i] - 1  \n        new_lst[new_index] = value\n    return new_lst\n\ndef address_augmentation(list_bloc, list_order):\n    \n    list_bloc[-1] = generate_rand_garbage(list_bloc)\n    list_bloc[2] = generate_rand_box(list_bloc)\n    # Pour la rue, remplacer des mots par une de leurs possibles abréviations\n    # importer / creer json de toutes les abréviations possibles\n    # print(list_bloc)\n    list_bloc = del_symbols(list_bloc.copy())\n    # print(list_bloc)\n    list_bloc = add_typo_error(list_bloc.copy(), list_order)\n    # print(list_bloc)\n    list_elem_cat = generate_elem_category(list_bloc)\n    rand_presence = generate_rand_presence(list_bloc)\n    rand_order = generate_rand_order(list_bloc)\n    \n    list_bloc_ordered = change_list_order(list_bloc,rand_order)\n    list_elem_cat_ordered = change_list_order(list_elem_cat,rand_order)\n    rand_presence_ordered = change_list_order(rand_presence,rand_order)\n    \n    list_final_category = []\n    string_final = ''\n    for i in range(len(rand_presence_ordered)):\n        if rand_presence_ordered[i] == 1:\n            if list_bloc_ordered[i] is None:\n                list_final_category.append(list_elem_cat_ordered[i])\n            elif len(list_bloc_ordered[i].strip()) != 0: \n                list_final_category.append(list_elem_cat_ordered[i])\n            if list_bloc_ordered[i] is not None and i==0:\n                string_final = list_bloc_ordered[i]\n            elif list_bloc_ordered[i] is not None:\n                string_final = string_final + ' ' + list_bloc_ordered[i]\n    string_final = string_final.strip()\n    words = string_final.split()\n    string_final = ' '.join(words)\n    flattened_list_final_category = [element for sublist in list_final_category for element in sublist]\n    \n    return string_final, flattened_list_final_category","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install pytest\n!pip install mock","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from unittest import mock\n\n# ['StreetName','StreetNumber','Unit','PostalCode','Municipality','GeneralDelivery']\nlist_bloc1 = ['86','Avenue des Camélias','','1150','Woluwé-Saint-Pierre','']\nlist_bloc2 = ['22','Belgielaan','','1800','Vilvoorde','']\nlist_bloc3 = ['115','Rue inventée','4','1200','Woluwé-Saint-Lambert','Boutique de jouets']\nlist_bloc4 = ['8','Avenue de Boileau','5','1160','Auderghem','Magasin de vêtements de Auderghem']\nlist_bloc5 = ['8','Avenue de Boileau','5','1160','Auderghem','']\nlist_bloc6 = ['115','Rue inventée','4','1200','Woluwé-Saint-Lambert','']\n\n# test part\ndef test_generate_rand_garbage():\n    with mock.patch('random.choice') as mock_choice:\n        mock_choice.side_effect = ['',' de ' + list_bloc1[4]]\n        g = generate_rand_garbage(list_bloc1)\n        assert g == '', g\n    with mock.patch('random.choice') as mock_choice:\n        mock_choice.side_effect = ['Bibliothèque', ' de ' + list_bloc2[4]]\n        g = generate_rand_garbage(list_bloc2)\n        assert g == 'Bibliothèque de Vilvoorde', g\n\ndef test_del_symbols():\n    g1 = del_symbols(list_bloc1)\n    assert g1 == ['86','Avenue des Camélias','','1150','Woluwé Saint Pierre',''], g1\n    g2 = del_symbols(list_bloc6)\n    assert g2 == ['115','Rue inventée','4','1200','Woluwé Saint Lambert',''], g2\n\ndef test_generate_rand_presence():\n    g1 = generate_rand_presence(list_bloc1)\n    assert sum(g1) <= 6, g1\n    g2 = generate_rand_presence(list_bloc2)\n    assert sum(g2) >= 0, g2\n\ndef test_generate_rand_order():\n    g = generate_rand_order(list_bloc3)\n    g_sorted = sorted(g)\n    assert g_sorted == [1,2,3,4,5,6], g\n\n'''\ndef test_add_typo_error():\n    with mock.patch('random.randint') as mock_index, \\\n         mock.patch('random.choice') as mock_choice:  \n        mock_index.return_value = 5\n        mock_choice.return_value = 'delete'\n        assert add_typo_error(list_bloc) == \n'''\n\n# ['8','Avenue de Boileau','5','1160','Auderghem','Magasin de vêtements de Auderghem']\ndef test_generate_elem_category():\n    g = generate_elem_category(list_bloc4, list_order = ['StreetNumber','StreetName','Unit','PostalCode','Municipality','GeneralDelivery'])\n    assert g == \\\n        [['StreetNumber'],['StreetName','StreetName','StreetName'],['Unit'],['PostalCode'],['Municipality'],['GeneralDelivery','GeneralDelivery','GeneralDelivery','GeneralDelivery','GeneralDelivery']], g\n\n\"\"\"\ndef test_change_list_order():\n    assert change_list_order(lst, order) == \n\ndef test_address_augmentation():\n    assert address_augmentation(list_bloc) == \n\"\"\"\n\ntest_generate_rand_garbage()\ntest_del_symbols()\ntest_generate_rand_presence()\ntest_generate_rand_order()\ntest_generate_elem_category()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_add = [list_bloc1,list_bloc2,list_bloc3,list_bloc4,list_bloc5,list_bloc6]\nlist_order = ['StreetNumber','StreetName','Unit','PostalCode','Municipality','GeneralDelivery']\nprint(list_add)\nfor s in list_add:    \n    # print(s)\n    # print(type(s))\n    # print(len(s))\n    print(address_augmentation(s,list_order))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dataset Preprocessing part 1: join muni and best","metadata":{}},{"cell_type":"code","source":"df_muni = pd.read_csv('/kaggle/input/municipalities/muni.csv')\ndf_muni = df_muni.astype(str)\ndf_muni = df_muni.replace('nan', None)\ndf_muni.columns = 'muni_' + df_muni.columns\ndf_muni['muni_validity_from'] = pd.to_datetime(df_muni['muni_validity_from'])\ndf_muni = df_muni.sort_values('muni_validity_from', ascending=False)\ndf_muni = df_muni.drop_duplicates(subset='muni_muni_code',keep='first').reset_index()\nprint(df_muni)\n\n# df_muni = df_muni[['muni_muni_code','muni_name_fr','muni_name_nl', 'muni_name_de']]\n\ndf_muni_fr= df_muni[['muni_muni_code','muni_name_fr']]\ndf_muni_fr.columns = ['muni_code','muni_name']\n\ndf_muni_nl= df_muni[['muni_muni_code','muni_name_nl']]\ndf_muni_nl.columns = ['muni_code','muni_name']\n\ndf_muni_de= df_muni[['muni_muni_code','muni_name_de']]\ndf_muni_de.columns = ['muni_code','muni_name']\n\ndel df_muni\ndf_muni = df_muni_fr\ndel df_muni_fr\ndf_muni = pd.concat([df_muni, df_muni_nl], axis=0)\ndel df_muni_nl\ndf_muni = pd.concat([df_muni, df_muni_de], axis=0)\ndel df_muni_de\n\ndf_muni.dropna(subset = ['muni_name'], inplace=True)\ndf_muni.drop_duplicates(subset = ['muni_name'], inplace=True)\n\nprint(df_muni)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_best = pd.read_csv('/kaggle/input/best-address/best.csv')\ndf_best = df_best.astype(str)\ndf_best = df_best.replace('nan', None)\ndf_best.columns = 'best_' + df_best.columns\n\ndf_best = df_best[['best_streetname_fr', 'best_streetname_nl',\n                  'best_streetname_de', 'best_house_number', 'best_box_number', 'best_muni_code', 'best_poco_code']]\n\ndf_best_fr = df_best[['best_streetname_fr','best_house_number', 'best_box_number', 'best_muni_code', 'best_poco_code']]\ndf_best_fr.columns = ['best_streetname','best_house_number', 'best_box_number', 'best_muni_code', 'best_poco_code']\ndf_best_nl = df_best[['best_streetname_nl','best_house_number', 'best_box_number', 'best_muni_code', 'best_poco_code']]\ndf_best_nl.columns = ['best_streetname','best_house_number', 'best_box_number', 'best_muni_code', 'best_poco_code']\ndf_best_de = df_best[['best_streetname_de','best_house_number', 'best_box_number', 'best_muni_code', 'best_poco_code']]\ndf_best_de.columns = ['best_streetname','best_house_number', 'best_box_number', 'best_muni_code', 'best_poco_code']\n\ndf_best = df_best_fr\ndel df_best_fr\ndf_best = pd.concat([df_best, df_best_nl], axis=0)\ndel df_best_nl\ndf_best = pd.concat([df_best, df_best_de], axis=0)\ndel df_best_de\n\ndf_best.dropna(subset = ['best_streetname'], inplace=True)\ndf_best.drop_duplicates(subset = ['best_streetname','best_house_number','best_box_number','best_muni_code','best_poco_code'], inplace=True)\n\nprint(df_best)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"address = pd.merge(df_best,df_muni,left_on=['best_muni_code'],right_on=['muni_code'])\ndel df_best\ndel df_muni\n# ['StreetNumber','StreetName','Unit','PostalCode','Municipality','GeneralDelivery']\naddress = address[['best_house_number',\\\n                   'best_streetname',\\\n                   'best_box_number',\\\n                   'best_poco_code',\\\n                   'muni_name']]\naddress['GeneralDelivery'] = ''\nprint(address)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(address.dtypes)\ntest = address.iloc[0:2].values.tolist()\nprint(test)\n# print(np.isnan(test[0][2]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"address_parser = AddressParser(model_type=\"bpemb\", device=0)\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dataset Preprocessing part 2: Augmentation","metadata":{}},{"cell_type":"code","source":"list_order = ['StreetNumber','StreetName','Unit','PostalCode','Municipality','GeneralDelivery']\n\nprint('debut part 1')\nlist_address = address.values.tolist()\nprint(len(list_address))\nprint('step1 fini')\n# prinst_address)\nlist_2_container = [] \n\nfor add in list_address:\n    inp, out = address_augmentation(add,list_order)\n    if inp == '' and out == []:\n        pass\n    elif (inp != '' and out == []) or (inp == '' and out != []):\n        raise 'mauvaise correspondance entre inp et out'\n    else:\n        list_2_container.append((inp, out))\n    # print([inp, out])\nprint('step2 fini')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(list_2_container[2]) \n\nrandom.shuffle(list_2_container)\n\nprint(list_2_container[2]) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dataset Preprocessing part 3: list to container","metadata":{}},{"cell_type":"code","source":"'''\naddress_parser.retrain(training_container,\n                       train_ratio=0.8,\n                       epochs=5,\n                       batch_size=8,\n                       num_workers=2,\n                       callbacks=[lr_scheduler],\n                       prediction_tags=tag_dictionary,\n                       logging_path=logging_path)\n'''\n'''\n# list_2_containerTEST = [('12 belgielaan bxA',['StreetNumber','StreetName','Unit']),\n#                     ('12 belgielaan bxA',['StreetNumber','StreetName','Unit'])]\n# container_train = deepparse.dataset_container.ListDatasetContainer(list_2_containerTEST)\nrandom.shuffle(list_2_container)\ncontainer_train = deepparse.dataset_container.ListDatasetContainer(list_2_container[:100000])\nprint(list_2_container[:10])\naddress_parser.retrain(container_train,\n                       train_ratio=0.8,\n                       epochs=14,\n                       batch_size=20)'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random.shuffle(list_2_container)\n\nbatch_size = 300000  # Number of rows to process in each iteration\n\ntotal_rows = len(list_2_container)\nnum_batches = (total_rows + batch_size - 1) // batch_size  # Calculate the number of batches\n\nN_epoch = address_parser.nb_epoch + 1\n\nfor batch_index in range(num_batches):\n    start_index = batch_index * batch_size\n    end_index = min((batch_index + 1) * batch_size, total_rows)\n    \n    batch = list_2_container[start_index:end_index]\n    \n    container_train = deepparse.dataset_container.ListDatasetContainer(batch)\n\n    address_parser.retrain(container_train,\n                           train_ratio=0.8,\n                           epochs=N_epoch,\n                           batch_size=25)\n    N_epoch = N_epoch + 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save model architecture as JSON\nmodel_json = address_parser.to_json()\nwith open(\"model_parserV1.json\", \"w\") as json_file:\n    json_file.write(model_json)\n\n# Save model weights\naddress_parser.save_weights(\"model_parserV1_weights.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_order = ['StreetNumber','StreetName','Unit','PostalCode','Municipality','GeneralDelivery']\n\nN_augmentation = 20\n\nfor u in range(N_augmentation):\n    print('debut part 1')\n    list_address = address.values.tolist()\n    print(len(list_address))\n    print('step1 fini')\n    # prinst_address)\n    list_2_container = [] \n\n    for add in list_address:\n        inp, out = address_augmentation(add,list_order)\n        if inp == '' and out == []:\n            pass\n        elif (inp != '' and out == []) or (inp == '' and out != []):\n            raise 'mauvaise correspondance entre inp et out'\n        else:\n            list_2_container.append((inp, out))\n        # print([inp, out])\n    print('step2 fini')\n    \n    random.shuffle(list_2_container)\n\n    batch_size = 100000  # Number of rows to process in each iteration\n    total_rows = len(list_2_container)\n    num_batches = (total_rows + batch_size - 1) // batch_size  # Calculate the number of batches\n\n    N_epoch = 15\n\n    for batch_index in range(num_batches):\n        start_index = batch_index * batch_size\n        end_index = min((batch_index + 1) * batch_size, total_rows)\n\n        batch = list_2_container[start_index:end_index]\n\n        container_train = deepparse.dataset_container.ListDatasetContainer(batch)\n\n        address_parser.retrain(container_train,\n                               train_ratio=0.8,\n                               epochs=N_epoch,\n                               batch_size=25)\n        N_epoch = N_epoch + 1","metadata":{},"execution_count":null,"outputs":[]}]}